<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://localhost:4000/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.3.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-04-29T11:28:23+08:00</updated><id>http://localhost:4000//</id><title type="html">夏虫</title><subtitle>夏天的一条虫</subtitle><entry><title type="html">录制cocos2d-x游戏画面（iOS）</title><link href="http://localhost:4000/jekyll/update/2017/04/29/cocos2d-x-texture-streaming.html" rel="alternate" type="text/html" title="录制cocos2d-x游戏画面（iOS）" /><published>2017-04-29T10:28:01+08:00</published><updated>2017-04-29T10:28:01+08:00</updated><id>http://localhost:4000/jekyll/update/2017/04/29/cocos2d-x-texture-streaming</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2017/04/29/cocos2d-x-texture-streaming.html">&lt;p&gt;最近要实现一个功能：录制cocos2d-x游戏的画面，然后通过RTMP协议推流上传。
(cocos2d-x是一个基于OpenGL ES 2.0的开源2D图像引擎)&lt;/p&gt;

&lt;p&gt;因为之前基于Metal做过类似的工作，所以首先想到的是OpenGL是否有类似Metal里面的“共享缓存”机制？。
首先查看官方的OpenGL编程指引：Apple:  OpenGL ES Programming Guide: Map Buffers into Client Memory for Fast Updates
文档指出了如何高效地在GPU和CPU之间共享buffer。但是遗憾的是，受限于OpenGL ES 2.x版本，这个方案仅仅能用来做vertex buffer，与Metal里的共享buffer相去甚远：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Buffer的长度最多仅为GL_BUFFER_SIZE，在iOS上，GL_BUFFER_SIZE=0x8764，根本没法用来放置纹理缓存；&lt;/li&gt;
  &lt;li&gt;shader不能修改buffer内容。
似乎比较鸡肋。
OpenGL ES 4.x提供了另一种用来在GPU和CPU之间共享buffer的方法：glMapBufferRange。
通过glGenBuffers方法创建，然后glBindBuffer绑定，最后通过glMapBufferRange（映射参数需要指定GL_MAP_COHERENT_BIT和GL_MAP_PERSISTENT_BIT）来更新或者获取GPU处理后的结果。
但是OpenGL ES 2不能使用，虽然Apple在OpenGL ES 2的extension里加入了glMapBufferRangeExt方法，但是却并不能指定映射参数，实际上效果还是和前面文档说到的方案一样。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;实际上与Metal里对应的应该是Shader Storage Buffer Object（SSBO）https://www.khronos.org/opengl/wiki/Shader_Storage_Buffer_Object
这种buffer的size比较大，而且支持shader读写操作，但是仅支持OpenGL ES 4，而iOS最高仅支持OpenGL ES 3，所以用不了这个。（这样看来，Metal大致与OpenGL ES 4.x平级啊）&lt;/p&gt;

&lt;p&gt;一开始想到的是readpixel，但是这个方法会阻塞CPU，导致CPU占用非常高，不适用。&lt;/p&gt;

&lt;p&gt;Apple有一套自己的基于纹理的GPU CPU数据共享机制，Metal的是CVMetalTextureCacheRef, OpenGL的是CVOpenGLESTextureCacheRef。
Unity3D引擎充分利用了这两种cache，封装了一个对上层透明的统一texture cache层，但是cocos2d-x没有用到。
对OpenGL ES，Apple官方的说明指出其用途是用来做输入的，即传送给GPU的数据，在CPU端修改之后，可以快速地传递到GPU端；而实际上，&lt;a href=&quot;http://stackoverflow.com/a/9704392&quot;&gt;这个Cache也是可以用作输出的！&lt;/a&gt;如果输出不能cache，那么每次都要做一次memcpy操作，很浪费CPU时间；另一方面，如果这个Cache只能用做输入，那岂不是很鸡肋？纹理数据一般变动比较小，基本上传递给GPU之后就可以丢弃了，后续很少更新。&lt;/p&gt;

&lt;h2 id=&quot;前期方案&quot;&gt;前期方案：&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;采用类似Metal的接口的blit操作，但是因为接口仅支持OpenGL ES 3.x 放弃&lt;/li&gt;
  &lt;li&gt;readpixel方案：占用CPU过多&lt;/li&gt;
  &lt;li&gt;采用texture cache 将fbo缓存到texture中 不可行&lt;/li&gt;
  &lt;li&gt;eagle context绘制两份 一份到fbo 一份到texture cache，因为cocos2d之前的绘制操作都绑定到一个fbo上面 绘制两份会导致texture cache的数据为空&lt;/li&gt;
  &lt;li&gt;可否将fbo复制？不可行&lt;/li&gt;
  &lt;li&gt;最终方案：先绘制到texture cache，再将texture绘制上屏&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;遇到的问题&quot;&gt;遇到的问题&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;shader不能在cocos初始化的时候就编译链接 必须重新创建一个program 幸好program之间的fbo texture等数据是共享的&lt;/li&gt;
  &lt;li&gt;如何将Cocos原有的绘制操作最终绘到创建的纹理缓存上而不是屏幕上面呢？关键点：context以及renderbuffer。在启动的时候动态替换到Cocos的初始化方法&lt;/li&gt;
  &lt;li&gt;如何将纹理绘制到屏幕上 需要绑定renderbuffer 类似2&lt;/li&gt;
  &lt;li&gt;如何做纹理的缩放？目前仅支持对纹理缩小。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;最终方案&quot;&gt;最终方案&lt;/h2&gt;
&lt;p&gt;最终的方案如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/image/cocos2d-x-texture-streaming-1.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与最初的设想相比，我做了如下几点改动：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;用于过渡的renderbuffer没有采用cache，而是一个标准的OpenGL texture；&lt;/li&gt;
  &lt;li&gt;使用VBO(vetex buffer object)。最开始的时候，我是按照Apple的文档Best Practicles for Working with Vetex Data上面的示例来绘制纹理的，并没有使用VBO，在Cocos2d-x 3.x版本上工作良好，但是在2.x版本上会触发内存读取错误，程序挂在了cocos2d-x内部一个glVertexAttribPointer方法上，后来我将程序完全使用VBO来实现，能同时适配两个版本。至于原因，有待进一步的探查。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;部分代码如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;绘制缓存纹理:
    &lt;pre&gt;&lt;code class=&quot;language-Objective-C&quot;&gt;- (void)renderCachedTextureScale {
 CHECK_GL_ERROR;
    
 if (colorRenderbuffer_ == 0) {
     NSLog(@&quot;offscreen frame buffer not prepared&quot;);
     return;
 }
    
 CGSize resolution = [[QGRTMPClient sharedClient] videResolution];
 CGFloat videoWidth = resolution.width;
 CGFloat videoHeight = resolution.height;
    
 glUseProgram(self.textureProgramScale);
 glBindFramebuffer(GL_FRAMEBUFFER, self.textureFramebufferScale);
 glBindRenderbuffer(GL_RENDERBUFFER, self.textureRenderbufferScale);
 CHECK_GL_ERROR;
    
 glViewport(0, 0, videoWidth, videoHeight);
    
 glBindTexture(GL_TEXTURE_2D, colorRenderbuffer_);
 CHECK_GL_ERROR;
    
 glBindBuffer(GL_ARRAY_BUFFER, self.textureVBScale);
 CHECK_GL_ERROR;

 glVertexAttribPointer(self.textureCoordsSlotScale,
                       2,
                       GL_FLOAT,
                       GL_FALSE,
                       sizeof(VertexBuffer),
                       (void *)offsetof(VertexBuffer, Coords));
 glEnableVertexAttribArray(self.textureCoordsSlotScale);
 CHECK_GL_ERROR;

 glVertexAttribPointer(self.positionSlotScale,
                       2,
                       GL_FLOAT,
                       GL_FALSE,
                       sizeof(VertexBuffer),
                       (void *)offsetof(VertexBuffer, Position));
 glEnableVertexAttribArray(self.positionSlotScale);
 CHECK_GL_ERROR;

 glDrawArrays(GL_TRIANGLE_STRIP, 0, 4);
 CHECK_GL_ERROR;

 glBindTexture(GL_TEXTURE_2D, 0); // 使用完之后解绑
 glBindBuffer(GL_ARRAY_BUFFER, 0);
 glDisableVertexAttribArray(self.textureCoordsSlotScale);
 glDisableVertexAttribArray(self.positionSlotScale);
    
 CHECK_GL_ERROR;
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
  &lt;li&gt;用于缩放操作的program初始化:
    &lt;pre&gt;&lt;code class=&quot;language-Objective-C&quot;&gt;- (void)prepareTextureProgramScale {
 if (self.textureProgramScale &amp;gt; 0) {
     return;
 }
    
 // 1
 GLuint fragmentShader = [self compileShader: @&quot;\
                          precision mediump float;\
                          uniform sampler2D Texture;\
                          varying vec2 TextureCoordsOut;\
                          void main(void)\
                          {\
                             vec4 mask = texture2D(Texture, TextureCoordsOut);\
                             gl_FragColor = vec4(mask.rgb, 1.0);\
                          }&quot;
                                  withType:GL_FRAGMENT_SHADER];
    
 GLuint vertexShader = [self compileShader:@&quot;\
                        attribute vec2 Position;\
                        attribute vec2 TextureCoords;\
                        varying vec2 TextureCoordsOut;\
                        void main(void)\
                        {\
                           gl_Position = vec4(Position, 0, 1);\
                           TextureCoordsOut = vec2(TextureCoords.x, 1.0 - TextureCoords.y);\
                        }&quot;
                                    withType:GL_VERTEX_SHADER];
    
 // 2
 GLuint programHandle = glCreateProgram();
 glAttachShader(programHandle, fragmentShader);
 glAttachShader(programHandle, vertexShader);
 glLinkProgram(programHandle);
    
 // 3
 GLint linkSuccess;
 glGetProgramiv(programHandle, GL_LINK_STATUS, &amp;amp;linkSuccess);
 if (linkSuccess == GL_FALSE) {
     GLchar messages[256];
     glGetProgramInfoLog(programHandle, sizeof(messages), 0, &amp;amp;messages[0]);
     NSString *messageString = [NSString stringWithUTF8String:messages];
     NSLog(@&quot;[Error]%@&quot;, messageString);
 }
 CHECK_GL_ERROR;
    
 // 4
 glUseProgram(programHandle);
    
 // 5
 self.positionSlotScale = glGetAttribLocation(programHandle, &quot;Position&quot;);
 self.textureSlotScale = glGetUniformLocation(programHandle, &quot;Texture&quot;);
 self.textureCoordsSlotScale = glGetAttribLocation(programHandle, &quot;TextureCoords&quot;);

 glEnableVertexAttribArray(self.positionSlot);
 CHECK_GL_ERROR;
 self.textureProgramScale = programHandle;
    
 GLuint framebuffer = 0;
 glGenFramebuffers(1, &amp;amp;framebuffer);
 NSAssert(framebuffer, @&quot;Can't create texture frame buffer&quot;);
 self.textureFramebufferScale = framebuffer;
    
 glBindFramebuffer(GL_FRAMEBUFFER, self.textureFramebufferScale);
 //create scaled texture cache and store it
 CVPixelBufferRef buf = 0;
 self.textureRenderbufferScale = [self createTextureCacheStore:&amp;amp;buf];
 self.renderTargetPixelBuffer = buf;
 CHECK_GL_ERROR;

 glBindRenderbuffer(GL_RENDERBUFFER, self.textureRenderbufferScale);
 glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, self.textureRenderbufferScale, 0);
 CHECK_GL_ERROR;

 CGSize resolution = [[QGRTMPClient sharedClient] videResolution];
 int cacheTextureWidth = resolution.width;
 int cacheTextureHeight = resolution.height;
    
 NSLog(@&quot;cocos2d: scaled surface size: %dx%d&quot;, (int)cacheTextureWidth, (int)cacheTextureHeight);
    
 CHECK_GL_ERROR;
 if(self.textureDepthbufferScale == 0) {
     GLuint textureDepthbuffer = 0;
     glGenRenderbuffers(1, &amp;amp;textureDepthbuffer);
     self.textureDepthbufferScale = textureDepthbuffer;
     NSLog(@&quot;[Error]Can't create texture depth buffer&quot;);
 }
    
 glBindRenderbuffer(GL_RENDERBUFFER, self.textureDepthbufferScale);
 CHECK_GL_ERROR;

 glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT16, cacheTextureWidth, cacheTextureHeight);
 CHECK_GL_ERROR;

 glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, self.textureDepthbufferScale);
 CHECK_GL_ERROR;

 [self setupVBScale];
 CHECK_GL_ERROR;

 GLenum error;
 if((error = glCheckFramebufferStatus(GL_FRAMEBUFFER)) != GL_FRAMEBUFFER_COMPLETE) {
     NSLog(@&quot;[Error]Failed to make complete framebuffer object 0x%X&quot;, error);
 }
}
&lt;/code&gt;&lt;/pre&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><summary type="html">最近要实现一个功能：录制cocos2d-x游戏的画面，然后通过RTMP协议推流上传。
(cocos2d-x是一个基于OpenGL ES 2.0的开源2D图像引擎)</summary></entry><entry><title type="html">有关Unity iOS Metal插件渲染过程</title><link href="http://localhost:4000/jekyll/update/2017/02/08/unity-metal-plugin-render-process.html" rel="alternate" type="text/html" title="有关Unity iOS Metal插件渲染过程" /><published>2017-02-08T15:44:01+08:00</published><updated>2017-02-08T15:44:01+08:00</updated><id>http://localhost:4000/jekyll/update/2017/02/08/unity-metal-plugin-render-process</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2017/02/08/unity-metal-plugin-render-process.html">&lt;p&gt;最近在做一个Unity的iOS原生渲染插件，目标是将主摄像头的texture做简单处理之后传给CPU，参考了Unity官方提供的Demo（代码在&lt;a href=&quot;https://bitbucket.org/Unity-Technologies/iosnativecodesamples/src/0bcacd4605720fb8525eade3b3ab867d3bc558aa/Graphics/MetalNativeRenderingPlugin/?at=5.4-stable&quot;&gt;这里&lt;/a&gt;)。这个Demo的运行过程如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;主Camera下面挂载了一个脚本TestMetalPlugin，在其OnPreRender方法中，将屏幕的RenderBuffer传给native端，在其OnPostRender方法中，将渲染事件传递给native端，然后native端再将接下来第二步中获取到的g_TextureCopy最终渲染到屏幕上；&lt;/li&gt;
  &lt;li&gt;另外创建了一个TestCamera，在其OnPreRender方法中，将该摄像头的RenderBuffer传给native端，在其OnPostRender方法中，将渲染事件传递给native端，然后native端再将此时获取到的RenderBuffer（TestCamera的视野）Blit到另一个g_TextureCopy中，以供第一步使用。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个Demo很完善，模拟了native端对Unity texture处理的过程，以及native端绘制自定义texture的方法。但是，我自己仅仅需要获取到主Camera的纹理，而无须再将处理后的texture再传回，所以我将两个脚本合成了一个。但是，问题来了，我发现通过这种方式获取到帧数据，有一些并没有包含那些在Unity脚本中onGUI方法创建的UI控件。奇怪的是，我如果使用两个脚本的话，就没有这个问题。
Unity里面脚本方法有执行先后顺序之分，OnPreRender和OnPostRender方法执行的时间都比onGUI要早，也许这是问题的一部分原因，但是根源在于Unity里面渲染过程和脚本执行过程&lt;a href=&quot;https://docs.unity3d.com/ScriptReference/GL.IssuePluginEvent.html&quot;&gt;不在同一个线程里&lt;/a&gt;：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;
Rendering in Unity can be multithreaded if the platform and number of available CPUs will allow for it. When multithreaded rendering is used, the rendering API commands happen on a thread which is completely separate from the one that runs the scripts. Consequently, it is not possible for your plugin to start rendering immediately, since it might interfere with what the render thread is doing at the time.
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;脚本的GL.IssuePluginEvent()方法会dispatch到渲染线程来执行，这样就有可能有时序问题，因为这个时候渲染过程并没有真正结束，还有OnGUI方法没有执行。那为什么挂载两个脚本就解决问题了呢？那是因为Unity对每个摄像头都是单独绘制的。也就是说，主摄像头绘制完毕了之后才会启动TestCamera的绘制过程，两者互不干扰，由于渲染线程只有一个，因此，如果在一个摄像头的脚本里获取另一个摄像头的数据，这个时候那个摄像头必然已经绘制完毕，就不会有时序的问题了。&lt;/p&gt;</content><summary type="html">最近在做一个Unity的iOS原生渲染插件，目标是将主摄像头的texture做简单处理之后传给CPU，参考了Unity官方提供的Demo（代码在这里)。这个Demo的运行过程如下：

  主Camera下面挂载了一个脚本TestMetalPlugin，在其OnPreRender方法中，将屏幕的RenderBuffer传给native端，在其OnPostRender方法中，将渲染事件传递给native端，然后native端再将接下来第二步中获取到的g_TextureCopy最终渲染到屏幕上；
  另外创建了一个TestCamera，在其OnPreRender方法中，将该摄像头的RenderBuffer传给native端，在其OnPostRender方法中，将渲染事件传递给native端，然后native端再将此时获取到的RenderBuffer（TestCamera的视野）Blit到另一个g_TextureCopy中，以供第一步使用。</summary></entry><entry><title type="html">为什么移除了滚动隐藏导航栏的功能？</title><link href="http://localhost:4000/jekyll/update/2016/12/17/why-remove-scrolling-hide-navigationabr-function.html" rel="alternate" type="text/html" title="为什么移除了滚动隐藏导航栏的功能？" /><published>2016-12-17T22:44:01+08:00</published><updated>2016-12-17T22:44:01+08:00</updated><id>http://localhost:4000/jekyll/update/2016/12/17/why-remove-scrolling-hide-navigationabr-function</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2016/12/17/why-remove-scrolling-hide-navigationabr-function.html">&lt;p&gt;说起这个问题，我们应该先想想：我们为什么要隐藏导航栏？原因是隐藏了之后，页面的展示空间变得更大了，用户可以看到更多内容。但是这个页面并不是完整的，隐藏了导航栏，会给人一种不知身在何处的错觉。
因此，这个功能最好用在导航控制器的第一个页面上，因为第一个页面无需返回按钮，所以即使不展示导航栏，也是OK的。Music应用就是这么做的。&lt;/p&gt;

&lt;p&gt;如果非要这么做的话，那就要注意这种“隐藏”状态只是一个临时的中间状态，其他非浏览操作都必须恢复原始的状态，这就是为什么当你在全屏状态下的时候，无法通过左侧的边缘滑动手势返回到上一个页面，而必须先通过一次下滑操作使导航栏显示出来。&lt;/p&gt;

&lt;p&gt;非开发人员可能会问：为什么要多此一举，这个时候右滑返回有什么问题吗？这里有几点要说明一下。首先，从交互设计上来看，这种滑动返回很难提供一致性的体验。当前页面隐藏了导航栏，但是上一个页面却不一定。如果不一致，那样就会有一个过渡效果，那样不太好看。另外一点，iOS系统禁止在导航栏隐藏情况下右滑返回。当然，开发者也可以使用自己添加手势的方式绕过这个问题（实际上在saralin 1.8.2的开发前期我已经实现了这个），但是依然无法回避前述第一个问题，效果比较拙劣。&lt;/p&gt;

&lt;p&gt;导航栏的变化还有另一种方式，那就是改变透明度。效果如下：刚打开页面的时候，导航栏正常显示，当页面往上滚动到一定位置的时候，导航栏变的透明（有时候会有个渐变效果）。手机QQ里面的空间就是用的这种效果。&lt;/p&gt;</content><summary type="html">说起这个问题，我们应该先想想：我们为什么要隐藏导航栏？原因是隐藏了之后，页面的展示空间变得更大了，用户可以看到更多内容。但是这个页面并不是完整的，隐藏了导航栏，会给人一种不知身在何处的错觉。
因此，这个功能最好用在导航控制器的第一个页面上，因为第一个页面无需返回按钮，所以即使不展示导航栏，也是OK的。Music应用就是这么做的。</summary></entry><entry><title type="html">HTML应用的缺陷有哪些？</title><link href="http://localhost:4000/jekyll/update/2016/12/11/drawbacks-of-html-applications.html" rel="alternate" type="text/html" title="HTML应用的缺陷有哪些？" /><published>2016-12-11T22:44:01+08:00</published><updated>2016-12-11T22:44:01+08:00</updated><id>http://localhost:4000/jekyll/update/2016/12/11/drawbacks-of-html-applications</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2016/12/11/drawbacks-of-html-applications.html">&lt;p&gt;首先声明，我不是一个前端开发，虽然我自己对前端技术很感兴趣，但是我自己也只是懂一点点皮毛，大部分问题还是靠Google，SO和MDN来解决。另外，我自己对框架完全不了解，最近在看angularJS。这里仅说说我在saralin开发中遇到的的自己觉得不太爽的一些例子。&lt;/p&gt;

&lt;h2 id=&quot;滚动加载更多的问题&quot;&gt;滚动加载更多的问题&lt;/h2&gt;
&lt;p&gt;Saralin的帖子详情页面是通过webview加载一个静态网页来展示的。在saralin早先版本中，网页加载完毕之后，页面就不再与webview控制器（webview controller）交互了。在1.8版本中，我加入了动态加载更多内容这一功能。1.8.1加入了向下加载更多，1.8.2加入了向上（即反向）加载更旧的内容，问题主要出在后者。
为了保持在插入新的dom节点之后页面停留在原位置不动，我们需要修改页面的scroll offset，类似下面这样：&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;oldHeight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;clientHeight&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;oldScrollOffset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;scrollTop&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//insert new dom&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;newHeight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;client&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;clientHeight&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;newScrollOffset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;scrollTop&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;//set offset&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;scrollTop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;newScrollOffset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;newHeight&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;–&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;oldHeight&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;问题在于有时候这样做会失效，导致页面直接滚动到了最顶端。我怀疑是因为我自己手指仍停留在网页上，所以滚动并没有终止，iOS系统为了保持滚动的连贯性，会自动设置网页scrollView的scrollOffset，而这一操作在我设置scrollTop之后，从而导致我的设置被覆盖了。
为了解决这个问题，我现在将插入dom节点的时机选在松手之后（即页面的touchend事件），当然如果当时已经没有手指放在屏幕上，那就直接插入dom节点，然后设置scrollTop属性。&lt;/p&gt;

&lt;h2 id=&quot;数据刷新的问题&quot;&gt;数据刷新的问题&lt;/h2&gt;
&lt;p&gt;我一直想把帖子详情页面做成一个类似于原生的UITableView一样的组件。但是在开发过程中,我发现了一些功能上的不足。
首先是缺少一种数据刷新的回调。UITableView可以通过各种delegate方法来获知cell重新被展示，但是web却只有一个onload事件。当我滚动到某一个element显示的时候，我无法对这个element变更外观。例如，一个展示发帖时间的span，我总不可能在页面初始化设置好了之后就不再改变这个值了吧？除非显示绝对时间，但是那种时间格式太难看了（“2016-11-23 12:45”，我觉得我宁愿不要看到这样子的时间）。一般都是显示模糊时间，例如“3分钟前”。我很奇怪为什么HTML没有一种可以定时收到回调的element,那样的话就可以完美解决上述问题。我现在的做法是定时遍历所有时间span，然后逐个更新。&lt;/p&gt;

&lt;h2 id=&quot;onscroll回调事件&quot;&gt;onscroll回调事件&lt;/h2&gt;
&lt;p&gt;onscroll事件在UIWebview和WKWebview中行为不一样，在UIWebview中，onscroll回调事件在滚动的中途并不会被调用，而WKWebview不存在这一问题。参见：&lt;a href=&quot;https://github.com/twbs/bootstrap/issues/16202&quot;&gt;Affix doesn’t update in iOS UIWebview&lt;/a&gt;&lt;/p&gt;</content><summary type="html">首先声明，我不是一个前端开发，虽然我自己对前端技术很感兴趣，但是我自己也只是懂一点点皮毛，大部分问题还是靠Google，SO和MDN来解决。另外，我自己对框架完全不了解，最近在看angularJS。这里仅说说我在saralin开发中遇到的的自己觉得不太爽的一些例子。</summary></entry></feed>
